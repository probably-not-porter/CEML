{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Software 0.1 Demo\n",
    "### CS488 - March 2020 - Porter Libby \n",
    "My environment includes the imports listed below in Python 3.7.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORTS ----------\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from PIL import Image\n",
    "from fastai.vision import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "import argparse\n",
    "import glob\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress bars\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CHANNEL COMPRESSION ----------\n",
    "\n",
    "def createMultiChannelImage(fpArr):\n",
    "    ''' Open multiple images and return a single multi channel image '''\n",
    "    mat = None\n",
    "    nChannels = len(fpArr)\n",
    "    for i,fp in enumerate(fpArr):\n",
    "        #print('Loading: ', fp)\n",
    "        img = PIL.Image.open(fp)\n",
    "        chan = pil2tensor(img, np.float32).float().div_(255)\n",
    "        if(mat is None):\n",
    "            mat = torch.zeros((nChannels,chan.shape[1],chan.shape[2]))\n",
    "        mat[i,:,:]=chan\n",
    "    return Image(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMAGE PREPROCESSOR ----------\n",
    "\n",
    "def image_preprocess(in_path):\n",
    "    \"\"\" Takes a directory path, returns three base versions of image. \"\"\"\n",
    "    image = cv2.imread(in_path) \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EDGE OPERATORS ----------\n",
    "\n",
    "# --- OpenCV2\n",
    "def canny_auto(in_path, sigma=0.33):\n",
    "    #print(\"Creating canny_auto...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    v = np.median(img)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    cannyauto = cv2.Canny(img, lower, upper)\n",
    "    cv2.imwrite('tmp/canny_auto.jpg', cannyauto)\n",
    "    return 'tmp/canny_auto.jpg'\n",
    "def canny_wide(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating canny_wide...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    cannywide = cv2.Canny(img, 10, 200)\n",
    "    cv2.imwrite('tmp/canny_wide.jpg', cannywide)\n",
    "    return 'tmp/canny_wide.jpg'\n",
    "def canny_tight(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating canny_tight...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    cannytight = cv2.Canny(img, 225, 250)\n",
    "    cv2.imwrite('tmp/canny_tight.jpg', cannytight)\n",
    "    return 'tmp/canny_tight.jpg'\n",
    "def laplacian(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating laplacian...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    lap = cv2.Laplacian(img,cv2.CV_64F)\n",
    "    cv2.imwrite('tmp/laplacian.jpg', lap)\n",
    "    return 'tmp/laplacian.jpg'\n",
    "def sobel_x(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating sobel_x...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\n",
    "    cv2.imwrite('tmp/sobel_x.jpg', sobelx)\n",
    "    return 'tmp/sobel_x.jpg'\n",
    "def sobel_y(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating sobel_y...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n",
    "    cv2.imwrite('tmp/sobel_y.jpg', sobely)\n",
    "    return 'tmp/sobel_y.jpg'\n",
    "\n",
    "# --- Scipy\n",
    "def prewitt(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating prewitt...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    p = ndi.prewitt(img) \n",
    "    cv2.imwrite('tmp/prewitt.jpg', p)\n",
    "    return 'tmp/prewitt.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMAGE PROCESSING HANDLERS ----------\n",
    "\n",
    "def createSingleInput(path):\n",
    "    img = createMultiChannelImage([\n",
    "        prewitt(path),\n",
    "        laplacian(path),\n",
    "        canny_tight(path)\n",
    "    ])\n",
    "    img.save('out/COMP.jpg')\n",
    "    print('Done!')\n",
    "    return img\n",
    "\n",
    "def createMultipleInput(path_ls,out_path):\n",
    "    imgs = []\n",
    "    for x in range(len(path_ls)):\n",
    "        update_progress(x / len(path_ls))\n",
    "        img = createMultiChannelImage([\n",
    "            prewitt(path_ls[x]),\n",
    "            canny_auto(path_ls[x]),\n",
    "            sobel_x(path_ls[x])\n",
    "        ])\n",
    "        img.save(out_path+str(x)+'.jpg')\n",
    "        imgs.append(img)\n",
    "    print('Done!')\n",
    "    return imgs\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    paths = []\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            paths.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "    return paths\n",
    "        \n",
    "def preprocessDatabase(path): # top level folder as input\n",
    "    subfolders = [ f.path for f in os.scandir(path) if f.is_dir() ]\n",
    "    for label in subfolders:\n",
    "        imgs = []\n",
    "        for file in os.listdir(label):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                imgs.append(os.path.join(label, file))\n",
    "                \n",
    "        dirpath = os.path.join(\"out\", label.split('/')[-1])\n",
    "        \n",
    "        if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "            shutil.rmtree(dirpath)\n",
    "        os.mkdir(dirpath)\n",
    "        \n",
    "        createMultipleInput(imgs, \"out/\"+label.split('/')[-1]+\"/\")\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONVOLUTIONAL NEURAL NETWORK ----------\n",
    "def CreateModelFromPath(path, folder_stats=True, image_stats=True):  #\n",
    "    size = 224\n",
    "    bs = 4\n",
    "    data = ImageDataBunch.from_folder(path, \n",
    "        ds_tfms=get_transforms(do_flip=True, flip_vert=True),\n",
    "        valid_pct=0.5, \n",
    "        size=size, \n",
    "        bs=bs)\n",
    "    \n",
    "    if folder_stats:\n",
    "        labels = os.listdir(path)\n",
    "        print(\"No. of labels: {}\".format(len(labels)))\n",
    "        print(\"-----------------\")\n",
    "        for label in labels:\n",
    "            print(\"{}, {} files\".format(label, len(os.listdir(path+label))))\n",
    "\n",
    "    if image_stats:\n",
    "        print(\"\\n Data to be run:\")\n",
    "        print(\"-----------------\")\n",
    "        data.normalize(imagenet_stats)\n",
    "        data.show_batch(rows=3, figsize=(3,3))\n",
    "        data.classes\n",
    "\n",
    "    # Create CNN Learner\n",
    "    learner = cnn_learner(data, models.resnet34, metrics=[accuracy])\n",
    "    learner.fit_one_cycle(5,max_lr=1e-2)\n",
    "    interp = ClassificationInterpretation.from_learner(learner)\n",
    "    interp.plot_confusion_matrix(figsize=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO - Pre-processing & Edge Detection\n",
    "\n",
    "Take an input path and create a parallel set of same-name folders with the processed versions of images.\n",
    "\n",
    "Settings are hard coded for this example.\n",
    "\n",
    "Processed images will be a channel compression of the following operations:\n",
    "- prewitt\n",
    "- canny_auto\n",
    "- sobel_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [#############-------] 66.3%\n"
     ]
    }
   ],
   "source": [
    "preprocessDatabase(\"../training/plant-id/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO - Machine Learning\n",
    "\n",
    "This step will create a resnet34 model based on the input path given.\n",
    "\n",
    "Settings are hard coded for this example.\n",
    "\n",
    "Model will do 5 learning cycles and then output confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 49:20<12:20]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.054363</td>\n",
       "      <td>0.758447</td>\n",
       "      <td>0.751079</td>\n",
       "      <td>12:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.822289</td>\n",
       "      <td>0.456308</td>\n",
       "      <td>0.855626</td>\n",
       "      <td>12:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518745</td>\n",
       "      <td>0.305763</td>\n",
       "      <td>0.882177</td>\n",
       "      <td>12:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.395875</td>\n",
       "      <td>0.281710</td>\n",
       "      <td>0.895121</td>\n",
       "      <td>12:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='667' class='' max='754', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      88.46% [667/754 03:06<00:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CreateModelFromPath(\"out\", False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit67e9689113b54fe08a64600d6234199b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

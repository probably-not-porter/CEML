{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline March 2020\n",
    "My environment includes the imports listed below in Python 3.7.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- IMPORTS ----------------------------\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse, glob, cv2, time, os, sys, shutil\n",
    "\n",
    "from PIL import Image\n",
    "from fastai.vision import *\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------- JUPYTER UTIL --------------------------\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "    \n",
    "# ----------------------- CHANNEL COMPRESSION -----------------------\n",
    "def createMultiChannelImage(fpArr):\n",
    "    ''' Open multiple images and return a single multi channel image '''\n",
    "    mat = None\n",
    "    nChannels = len(fpArr)\n",
    "    for i,fp in enumerate(fpArr):\n",
    "        #print('Loading: ', fp)\n",
    "        img = PIL.Image.open(fp)\n",
    "        chan = pil2tensor(img, np.float32).float().div_(255)\n",
    "        if(mat is None):\n",
    "            mat = torch.zeros((nChannels,chan.shape[1],chan.shape[2]))\n",
    "        mat[i,:,:]=chan\n",
    "    return Image(mat)\n",
    "\n",
    "# ----------------------- IMAGE PREPROCESSOR -----------------------\n",
    "def image_preprocess(in_path):\n",
    "    \"\"\" Takes a directory path, returns three base versions of image. \"\"\"\n",
    "    image = cv2.imread(in_path) \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "    return blurred\n",
    "\n",
    "# ----------------------- PROCESSING ALGORITHMS -----------------------\n",
    "# --- OpenCV2\n",
    "def canny_auto(in_path, sigma=0.33):\n",
    "    #print(\"Creating canny_auto...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    v = np.median(img)\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    cannyauto = cv2.Canny(img, lower, upper)\n",
    "    cv2.imwrite('tmp/canny_auto.jpg', cannyauto)\n",
    "    return 'tmp/canny_auto.jpg'\n",
    "def canny_wide(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating canny_wide...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    cannywide = cv2.Canny(img, 10, 200)\n",
    "    cv2.imwrite('tmp/canny_wide.jpg', cannywide)\n",
    "    return 'tmp/canny_wide.jpg'\n",
    "def canny_tight(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating canny_tight...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    cannytight = cv2.Canny(img, 225, 250)\n",
    "    cv2.imwrite('tmp/canny_tight.jpg', cannytight)\n",
    "    return 'tmp/canny_tight.jpg'\n",
    "def laplacian(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating laplacian...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    lap = cv2.Laplacian(img,cv2.CV_64F)\n",
    "    cv2.imwrite('tmp/laplacian.jpg', lap)\n",
    "    return 'tmp/laplacian.jpg'\n",
    "def sobel_x(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating sobel_x...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)  # x\n",
    "    cv2.imwrite('tmp/sobel_x.jpg', sobelx)\n",
    "    return 'tmp/sobel_x.jpg'\n",
    "def sobel_y(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating sobel_y...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)  # y\n",
    "    cv2.imwrite('tmp/sobel_y.jpg', sobely)\n",
    "    return 'tmp/sobel_y.jpg'\n",
    "\n",
    "# --- Scipy\n",
    "def prewitt(in_path):\n",
    "    \"\"\" Take a directory path, writes result to another path \"\"\"\n",
    "    #print(\"Creating prewitt...\")\n",
    "    img = image_preprocess(in_path)\n",
    "    p = ndi.prewitt(img) \n",
    "    cv2.imwrite('tmp/prewitt.jpg', p)\n",
    "    return 'tmp/prewitt.jpg'\n",
    "\n",
    "\n",
    "# ----------------------- HANDLERS FOR PROCESSING -----------------------\n",
    "def createSingleInput(path):\n",
    "    img = createMultiChannelImage([\n",
    "        prewitt(path),\n",
    "        laplacian(path),\n",
    "        canny_tight(path)\n",
    "    ])\n",
    "    img.save('out/COMP.jpg')\n",
    "    #print('Done!')\n",
    "    return img\n",
    "\n",
    "def createMultipleInput(path_ls,out_path, settings):\n",
    "    imgs = []\n",
    "    for x in range(len(path_ls)):\n",
    "        img_layers = []\n",
    "        if settings[0] == True:\n",
    "            img_layers.append(canny_tight(path_ls[x]))\n",
    "            \n",
    "        if settings[1] == True:\n",
    "            img_layers.append(canny_auto(path_ls[x]))\n",
    "            \n",
    "        if settings[2] == True:\n",
    "            img_layers.append(canny_wide(path_ls[x]))\n",
    "            \n",
    "        if settings[3] == True:\n",
    "            img_layers.append(laplacian(path_ls[x]))\n",
    "            \n",
    "        if settings[4] == True:\n",
    "            img_layers.append(sobel_x(path_ls[x]))\n",
    "            \n",
    "        if settings[5] == True:\n",
    "            img_layers.append(sobel_y(path_ls[x]))\n",
    "            \n",
    "        if settings[6] == True:\n",
    "            img_layers.append(prewitt(path_ls[x]))\n",
    "            \n",
    "        if len(img_layers) == 1:\n",
    "            img = PIL.Image.open(img_layers[0])  # single channel image\n",
    "            \n",
    "            img.save(out_path+str(x)+'.jpg')\n",
    "            imgs.append(img)\n",
    "            \n",
    "        else:\n",
    "            img = createMultiChannelImage([ # multi channel image\n",
    "                img_layers[0],\n",
    "                img_layers[1],\n",
    "                img_layers[2]\n",
    "            ])\n",
    "            img.save(out_path+str(x)+'.jpg')\n",
    "            imgs.append(img)\n",
    "    return imgs\n",
    "\n",
    "def absoluteFilePaths(directory):\n",
    "    paths = []\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            paths.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "    return paths\n",
    "        \n",
    "def preprocessDatabase(path, settings): # top level folder as input\n",
    "    if os.path.exists(\"out\") and os.path.isdir(\"out\"):    #check if path exists already\n",
    "            #print('REMOVING EXISTING PROCESSED DATABASE')\n",
    "            shutil.rmtree(\"out\")\n",
    "    os.mkdir(\"out\")\n",
    "    \n",
    "    subfolders = [ f.path for f in os.scandir(path) if f.is_dir() ]\n",
    "    for label in subfolders:\n",
    "        imgs = []\n",
    "        for file in os.listdir(label):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                imgs.append(os.path.join(label, file))\n",
    "                \n",
    "        dirpath = os.path.join(\"out\", label.split('/')[-1])\n",
    "        \n",
    "        if os.path.exists(dirpath) and os.path.isdir(dirpath):\n",
    "            shutil.rmtree(dirpath)\n",
    "        os.mkdir(dirpath)\n",
    "        \n",
    "        createMultipleInput(imgs, \"out/\"+label.split('/')[-1]+\"/\", settings)\n",
    "        \n",
    "# --------------------------- CNN MODEL ---------------------------\n",
    "def CreateModelFromPath(path, folder_stats=True, image_stats=True):  #\n",
    "    size = 224\n",
    "    bs = 4\n",
    "    data = ImageDataBunch.from_folder(path, \n",
    "        ds_tfms=get_transforms(do_flip=True, flip_vert=True),\n",
    "        valid_pct=0.5, \n",
    "        size=size, \n",
    "        bs=bs)\n",
    "    \n",
    "    data.show_batch(rows=3, figsize=(7,6))\n",
    "    \n",
    "    if folder_stats:\n",
    "        labels = os.listdir(path)\n",
    "        print(\"No. of labels: {}\".format(len(labels)))\n",
    "        print(\"-----------------\")\n",
    "        for label in labels:\n",
    "            print(\"{}, {} files\".format(label, len(os.listdir(path+label))))\n",
    "\n",
    "    if image_stats:\n",
    "        print(\"\\n Data to be run:\")\n",
    "        print(\"-----------------\")\n",
    "        data.normalize(imagenet_stats)\n",
    "        data.show_batch(rows=3, figsize=(3,3))\n",
    "        data.classes\n",
    "\n",
    "    # Create CNN Learner\n",
    "    learner = cnn_learner(data, models.resnet34, metrics=[accuracy, error_rate])\n",
    "    learner.fit_one_cycle(5)\n",
    "    learner.recorder.plot_lr()\n",
    "    learner.recorder.plot()\n",
    "    \n",
    "    interp = ClassificationInterpretation.from_learner(learner)\n",
    "    interp.plot_confusion_matrix(figsize=(3,3))\n",
    "    \n",
    "# ------------ QUEUE COMPLETE PIPELINE ---------------\n",
    "def pipeline(dataset_arr):\n",
    "    for path in dataset_arr:\n",
    "        print(\"processing data... (\" + path + \")\")\n",
    "        preprocessDatabase(path)\n",
    "        print(\"training model... (\" + path + \")\")\n",
    "        CreateModelFromPath(\"out\", False, False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata_sets = [\\n    \"../training/EC-small/\",\\n    \"../training/EC-small/\",\\n    \"../training/EC-small/\",\\n    \"../training/EC-small/\",\\n    \"../training/EC-small/\",\\n    \"../training/plant-id/\"\\n]\\npipeline(data_sets)\\n\\n# Testing sequence \\nprint(\"Testing Sequence\")\\n\\nprint(\"----- TEST 1: srsd -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"out\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 2: srsd -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"out\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 3: srsd -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"out\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 4: srsd -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"out\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 5: vli -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"../training/plant-id/\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 6: vli -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"../training/plant-id/\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 7: vli -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"../training/plant-id/\", False, False)\\ntime.sleep(180)\\n\\nprint(\"----- TEST 8: vli -----\")\\nprint(\"start time: \" + str(datetime.now()))\\nCreateModelFromPath(\"../training/plant-id/\", False, False)\\ntime.sleep(180)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOME TESTS\n",
    "# march 11\n",
    "# FULL PIPELINE FOR MULTIPLE SETS\n",
    "\"\"\"\n",
    "data_sets = [\n",
    "    \"../training/EC-small/\",\n",
    "    \"../training/EC-small/\",\n",
    "    \"../training/EC-small/\",\n",
    "    \"../training/EC-small/\",\n",
    "    \"../training/EC-small/\",\n",
    "    \"../training/plant-id/\"\n",
    "]\n",
    "pipeline(data_sets)\n",
    "\n",
    "# Testing sequence \n",
    "print(\"Testing Sequence\")\n",
    "\n",
    "print(\"----- TEST 1: srsd -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 2: srsd -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 3: srsd -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 4: srsd -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 5: vli -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"../training/plant-id/\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 6: vli -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"../training/plant-id/\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 7: vli -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"../training/plant-id/\", False, False)\n",
    "time.sleep(180)\n",
    "\n",
    "print(\"----- TEST 8: vli -----\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"../training/plant-id/\", False, False)\n",
    "time.sleep(180)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 1: Canny Tight\n",
      "start time: 2020-03-12 10:16:03.874206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/5 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='435' class='' max='753', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      57.77% [435/753 05:16<03:51 0.7941]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# march 12 tests\n",
    "print(\"TEST 1: Canny Tight\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [True,False,False,False,False,False,False]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "print(\"TEST 2: Canny Auto\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [False,True,False,False,False,False,False]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "print(\"TEST 3: Canny Wide\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [False,False,True,False,False,False,False]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "print(\"TEST 4: Laplacian\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [False,False,False,True,False,False,False]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "print(\"TEST 5: Sobel X\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [False,False,False,False,True,False,False]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "print(\"TEST 6: Sobel Y\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [False,False,False,False,False,True,False]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "print(\"TEST 7: Prewitt\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "algorithm_settings = [False,False,False,False,False,False,True]\n",
    "preprocessDatabase(\"../training/plant-id/\", algorithm_settings)\n",
    "CreateModelFromPath(\"out\", False, False)\n",
    "\n",
    "time.sleep(600) # cooldown\n",
    "\n",
    "# CONTROL\n",
    "print(\"TEST 7: CONTROL\")\n",
    "print(\"start time: \" + str(datetime.now()))\n",
    "CreateModelFromPath(\"../training/plant-id/\", False, False)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bit67e9689113b54fe08a64600d6234199b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
